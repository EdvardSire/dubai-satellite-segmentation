<p align="center"> 
<a href="https://github.com/Followb1ind1y"><img src="https://img.shields.io/static/v1?logo=github&label=maintainer&message=Followb1ind1y&color=eb5334" alt="Last Commit"/></a> 
<a href="https://github.com/Followb1ind1y/Semantic-Segmentation-of-Aerial-Imagery/graphs/commit-activity"><img src="https://img.shields.io/github/last-commit/Followb1ind1y/Semantic-Segmentation-of-Aerial-Imagery.svg?colorB=eb9f34&style=flat" alt="Last Commit"/> </a> 
<img src="https://img.shields.io/github/repo-size/Followb1ind1y/Semantic-Segmentation-of-Aerial-Imagery.svg?colorB=34ebae&style=flat" alt="Size"/>
<img src="https://img.shields.io/github/languages/top/Followb1ind1y/Semantic-Segmentation-of-Aerial-Imagery.svg?colorB=9f34eb&style=flat" alt="Language"/></a> 
</p>

<p align="center"> 
<a href="https://mybinder.org/v2/gh/Followb1ind1y/Semantic-Segmentation-of-Aerial-Imagery/HEAD"><img src="https://img.shields.io/badge/Open in-binder-579aca.svg?logo=data:image/png;base64,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" alt="binder"/></a>     
<a href="https://colab.research.google.com/github/Followb1ind1y/Semantic-Segmentation-of-Aerial-Imagery/blob/main/ML_Algorithms_Boosting.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="colab"/></a>       
</p>

# Semantic Segmentation of Aerial Imagery

## **About**

> Semantic segmentation, with the goal to assign semantic labels to every pixel in an image, is an essential computer vision task. In this project, we use semantic segmentation models to categorize content in aerial images of Dubai into six classes.

* Create custom datasets, dataloaders and transformers for semantic segmentation tasks.
* Build semantic segmentation models to classify an image at the pixel level. Implement performance metrics to keep tracking the training process.
* Test the model using aerial images of other cities.


## **Dataset**

All the training data used in this project are from [Semantic segmentation of aerial imagery](https://www.kaggle.com/datasets/humansintheloop/semantic-segmentation-of-aerial-imagery). The dataset consists of aerial imagery of Dubai obtained by MBRSC satellites and annotated with pixel-wise semantic segmentation in 6 classes (Building, Land, Road, etc.). The total volume of the dataset is 72 images grouped into 6 larger tiles. [UAVid Semantic Segmentation Dataset](https://www.kaggle.com/datasets/titan15555/uavid-semantic-segmentation-dataset) was also used to test the performance of the model.

<center><img src="img/example5.png" width=650px /></center>

##  **Preprocessing**

### **Cropping and Patchifying**

The total volume of the dataset is 72 images grouped into 8 larger tiles. To create a dataset with the same input size and for easier-to-apply data augmentation methods, we decomposed the original tiles into smaller patches (224*224). 2331 images and masks comprise the input dataset.

### **One-hot Encode Masks**
Since Class colours are in hex, whilst the mask images are in RGB. We need to convert the original masks in RGB and encode the output as integers for multi-class classification tasks. 

| Class | Class Name | Color Hex # | Color RGB |
|--|--|--|--|
|0|Unlabeled|9B9B9B|(226, 169, 41)|
|1|Building|3C1098|(60, 16, 152)|
|2|Land (unpaved area)|8429F6|(132, 41, 246)|
|3|Road|6EC1E4|(110, 193, 228)|
|4|Vegetation|FEDD3A|(254, 221, 58)|
|5|Water|E2A929|(80, 227, 194)|

## **Training Process**

* **Image Augmentation:** Apply mask augmentation methods for segmentation from `albumentations` (e.g. ShiftScaleRotate, RandomBrightnessContrast) on the train/val dataset.
* **Fine-Tuning Models:** Build the UNet model for multi-class semantic segmentation. Implement custom multiclass dice loss and mean IoU score functions. Train the image dataset using different pretrained encoders (e.g. resnet101, efficientnet-b4, mobilenet_v2).
* **Evaluation:** Evaluate the models on the test set and UAVid Semantic Segmentation Dataset. Display the predictions on images.

## **Results**

<center><img src="img/result.png" width=425px /></center>

## **Demonstration**

<center><img src="img/example1.png" width=550px /></center>
<center><img src="img/example3.png" width=550px /></center>
<center><img src="img/example4.png" width=550px /></center>

## Reference
> [1] Ronneberger, O., Fischer, P., &amp; Brox, T. (2015, May 18). U-Net: Convolutional Networks for Biomedical Image Segmentation. arXiv.org. Retrieved March 20, 2023, from `https://arxiv.org/abs/1505.04597`
>
> [2] Humans In The Loop. (2020, May 29). Semantic segmentation of aerial imagery. Kaggle. Retrieved March 20, 2023, from `https://www.kaggle.com/datasets/humansintheloop/semantic-segmentation-of-aerial-imagery` 
>
> [3] Schmidt, J. (2023, January 18). Creating and training a U-net model with Pytorch for 2D &amp; 3D Semantic Segmentation: Dataset... Medium. Retrieved March 20, 2023, from `https://towardsdatascience.com/creating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-dataset-fb1f7f80fe55`

## **Licence**

This repository is licensed under the Apache-2.0 License - see the [LICENSE](https://github.com/Followb1ind1y/Semantic-Segmentation-of-Aerial-Imagery/LICENSE) file for details.
